---
title: '【机器学习笔记】：模型性能度量'
date: 2024-04-17
permalink: /posts/2024/04/blog-model-performance-evaluation/
tags:
  - 机器学习
  - 西瓜书
  - 算法
---
<img src='/images/blog/2024-model-performance-evaluation/model-performance-evaluation-1.png'>

*本文主要内容，来自于本人在阅读周志华《机器学习》[1]这本书过程中，总结出来的重要知识点。*

在分类问题中，把分类错误的样本数占样本总数的比例称为“错误率（error rate）”，而分类正确的样本数占样本总数的比例则为“精度（accuracy）”，显然有“精度 + 错误率 = 1”。更一般地，我们把学习器的实际预测输出与样本的真实输出之间的差异称为“误差（error）“，学习器在训练集上的误差称为“训练误差（training error）”或“经验误差（empirical error）“，在新样本上的误差称为“泛化误差（generalization error）”。

我们希望学习器可以从训练样本中学习到适用于所有潜在样本的“普遍规律”，这样在遇到新样本的时候，学习器才能有很好的表现，即我们的目标是减小”泛化误差“。然而，有时候，在训练过程中，学习器把训练样本的所有特征都”记住“了，但是，遇到新样本时，却无法给出正确的判断，这种现象叫做”过拟合（overfitting）“。与”过拟合“相对的是”欠拟合（underfitting）“，即学习器没有从训练样本中总结出”普遍规律“。举个极端一点的例子，两个学生A和B参加考试，A很勤奋，记忆里很好，他把以前所有的考试题目的答案都背了下来，但是A最大的缺点就是脑子比较古板，不懂得变通，题目稍微改一下，他就束手无策了。而B则不同，他很懒，记忆里也不好，考试全靠蒙。想象一下，在一场考试中，如果题目全是从过去的考卷中摘抄来的，那么A肯定可以拿满分，而B靠着蒙，也能得到一些分数；如果所有的题目都是新题目，那么A只能拿0分，B却仍然可以靠蒙，得到一些分数。A同学的学习就是“过拟合”，B同学的学习就是“欠拟合”。

